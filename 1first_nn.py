# -*- coding: utf-8 -*-
"""FIRST_NN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YiBH-xGNyNsugGNGDamTXLc0E27ScNaQ
"""

import pandas as pd

df = pd.read_csv("/content/Churn_Modelling.csv")

df.sample()

df.isnull().sum()

df.info()

df.duplicated().sum()

df["Exited"].value_counts()

df = df.drop(columns = ["RowNumber",	"CustomerId", "Surname"] , axis = 0)

df = pd.get_dummies(df,columns=["Geography"	, "Gender"], drop_first = True)

df.sample(4)

x = df.drop(columns = ["Exited"])
y = df["Exited"]

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test = train_test_split(x,y)

from sklearn.preprocessing import StandardScaler
scalar = StandardScaler()

x_train_scalar = scalar.fit_transform(x_train) 
x_test_scalar = scalar.fit_transform(x_test)

import tensorflow
from tensorflow import keras
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense

model = Sequential()

model.add(Dense(3,activation='sigmoid',input_dim=11))
model.add(Dense(1,activation='sigmoid'))

model.summary()

model.compile(loss="binary_crossentropy" , optimizer = "Adam")

model.fit(x_train_scalar,y_train,epochs = 100)

model.layers[0].get_weights()

a = model.predict(x_test_scalar)

import numpy as np
y_pred = np.where(a>0.5,1,0)

from sklearn.metrics import accuracy_score
accuracy_score(y_test,y_pred)

#further we can do hyperparameter tunning